\section{Problem \thesection}

In the sample codes below, two different timing methods are shown. The first example
(Snippet \ref{lst:time1}) uses the
\code{timeit} module method \code{timeit} to time a single statement.
The statement is repeated \code{n} times to get the average time per call.

\begin{algorithm}
    \caption{Timing a bunch of mathematical expressions.}
    \label{lst:time1}
    \begin{pythoncode}
        def time1():
            setup = "import math"
            n = 10000000
            s = timeit.timeit(stmt='8967.4*15.4328', setup=setup, number=n)
            print('Time per multiplication call is:', float(s) / n)
            s = timeit.timeit(stmt='8967.4*15.4328+3567.2', setup=setup, number=n)
            print('Time per multiplication plus add call is:', float(s) / n)
            s = timeit.timeit(stmt='8967.4/15432.8', setup=setup, number=n)
            print('Time per division call is:', float(s) / n)
            s = timeit.timeit(stmt='math.cos(10)', setup=setup, number=n)
            print('Time per cos call is:', float(s) / n)
            s = timeit.timeit(stmt='math.log(10)', setup=setup, number=n)
            print('Time per log call is:', float(s) / n)
    \end{pythoncode}
\end{algorithm}

And the output is:

\begin{minted}[frame=lines]{text}
Time per multiplication call is: 5.673008299999971e-09
Time per multiplication plus add call is: 4.112341599999958e-09
Time per division call is: 4.108937500000032e-09
Time per cos call is: 4.9459925000000027e-08
Time per log call is: 6.079733750000003e-08
\end{minted}

Snippet \ref{lst:time2} uses two calls to the default timer to record the start and stop
time for code enclosed between these calls. Note that the arrays are created outside the
numeric calculation. The NumPy arrays used here are generally optimized for better numerical
performance than regular Python arrays or lists. Time a few different statements inside the
timer calls.

\begin{algorithm}
    \caption{Timing the mathematical operations on NumPy arrays.}
    \label{lst:time2}
    \begin{pythoncode}
        def time2():
            n = 1000000
            for _ in range(5):
                a = np.random.rand(n)
                b = np.random.rand(n)
            starttime = timeit.default_timer()
            print("The start time is:", starttime)
            c = a * np.log(b)
            dt = timeit.default_timer() - starttime
            print("The time difference is:", dt)
            print("The time per operation is:", dt / n)
    \end{pythoncode}
\end{algorithm}

And the output is:

\begin{minted}[frame=lines,autogobble]{text}
The start time is: 17.98673
The time difference is: 0.005920874999997494
The time per operation is: 5.920874999997494e-09
\end{minted}

\Question How do the times here, using NumPy, compare with the times for single
statements using \code{timeit}?

\Answer The operations in Snippet \ref{lst:time2} is basically at the same magnitude as
in Snippet \ref{lst:time1}. It is as if the whole operations are just applied to
on element. That means these NumPy operations are of $\mathcal{O}(1)$ complexity.
NumPy probably runs these operations in parallel.
If we change the NumPy arrays to normal Python lists, as shown in Snippet \ref{lst:time3}:

\begin{algorithm}[H]
    \caption{Timing the mathematical operations on Python lists.}
    \label{lst:time3}
    \begin{pythoncode}
        def time3():
            n = 1000
            a = np.random.rand(n)
            b = np.random.rand(n)
            a = a.tolist()
            b = b.tolist()
            starttime = timeit.default_timer()
            print("The start time is:", starttime)
            for i, j in zip(a, b):
                i * math.log(j)
            dt = timeit.default_timer() - starttime
            print("The time difference is:", dt)
            print("The time per operation is:", dt / n)
        \end{pythoncode}
\end{algorithm}

And the output is:

\begin{minted}[frame=lines,autogobble]{text}
    The start time is: 1229.515670041
    The time difference is: 0.00022004199990988127
    The time per operation is: 2.2004199990988126e-07
\end{minted}

As you can see, each operation is much slower. We could assume the operations is
of $\mathcal{O}(N)$ complexity.

\Question Now use the \code{timeit.default_timer()} calls to time the loop over random number
multiplications in Problem \ref{sec:p1}. Time the multiplication loop using standard
floating point numbers, the loop using truncation and the loop using rounding separately to
measure how much longer it takes to do the various additional operations in the truncation
and rounding case.

\Answer We plot the time the algorithm uses per loop ($t$) versus the number of
multiplications $n$ in Fig. \ref{fig:time_loop}. As you can see,
they almost all grow linearly with increasing $n$. The only difference is their slopes.
The standard floating point numbers multiplication is the fastest (and of course, the most
accurate). The truncated algorithm is a little slower, at the cost of losing
accuracy (compared to the rounded case). And the rounded algorithm is the slowest
among the three. The reason could be it repeatedly decomposes and composes numbers.
They all have almost constant slopes indicate that the time of each multiplication
is not getting slower no matter the number is either large or small.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{p2_q3}
    \caption{Time per loop $t$ as a function of number of multiplications $n$ of
        the multiplication loops using standard floating point numbers,
        truncation algorithm and rounding algorithm.}
    \label{fig:time_loop}
\end{figure}

\newpage
