\section{Problem \thesection}

Here you are to investigate back recursion to determine the modified Bessel function
$I_n(x)$.

\Question Write a program using back recursion to calculate $I_n(x)$.
Their values can be compared with the values determined by SciPy.
For $x$ in the range $1$ to $10$, how many back recursion steps are needed to
determine $I_0(x)$ to $I_5(x)$ to $6$ decimal places of accuracy?

\Answer First, we need to write a little program for the modified Bessel functions.
Since the \emph{normalizer} is
%
\begin{equation}\label{eq:normalize}
    1 = I_0(x) - 2 I_2(x) + 2 I_4(x) - 2 I_6(x) + \ldots,
\end{equation}
%
we need to write a little code, as shown in Snippet \ref{lst:normalize}.
The \code{coeff} function calculates each coefficient of the
modified Bessel functions: $\bm{c} = \irow{1 & 0 & -2 & 0 & 2 & -2 & 0 & 2 & \ldots}$.
And in function \code{normalize} we divide each order of the modified Bessel function
by a scaling factor, which is determined by the normalizer \eqref{eq:normalize}.

\begin{algorithm}
    \caption{Normalization algorithm for a series of modified Bessel functions.}
    \label{lst:normalize}
    \begin{pythoncode}
        def coeff(i):
            if i == 0:
                return 1
            elif i % 4 == 0:
                return 2
            elif i % 2 == 0:
                return -2
            else:
                return 0


        def normalize(I):
            coeffs = np.vectorize(coeff)(range(len(I)))
            scaling_factor = np.dot(coeffs, I)  # Return $\sum_i \bm{c}_i \bm{I}_i(x)$
            return I / scaling_factor  # Divide all values in $\bm{I}$ by the `scaling_factor`
    \end{pythoncode}
\end{algorithm}

Now we can write our back recursion algorithm, as shown in Snippet \ref{lst:back_recursion}.
In function \code{back_recursion}, we first initialize an empty vector \code{I} which
will store the values of the modified Bessel functions of each order up to
\code{max_order} (denoted as $N$, where $N \geq 2$) at $x$, i.e., $I_n(x)$, where
$n = 0, 1, \ldots, N$.
Then we set the last two values of \code{I} to be anything we want, i.e.,
$I_{N-1}(x) = 1$ and $I_N(x) = 0$ here,
since $I_n(x)$ at fixed $x$ decreases with increasing $n$.
And we work back to the first order using the recurrence relation:
%
\begin{equation}
    I_{n + 1}(x) = -\frac{ 2 n }{ x } I_n(x) + I_{n - 1}(x).
\end{equation}
%
At last, we normalize the series with normalizer \eqref{eq:normalize}.

\begin{algorithm}
    \caption{A naïve back recursion algorithm.}
    \label{lst:back_recursion}
    \begin{pythoncode}
        def back_recursion(x, starting_order):
            orders = range(starting_order + 1)
            I = np.empty(starting_order + 1)  # Orders from 0 to `starting_order`
            I[-2:] = 1, 0  # Set the last two values
            for n in np.flip(orders)[2:]:  # Orders from `starting_order-2` to 0
                I[n] = I[n + 2] + 2 * (n + 1) / x * I[n + 1]
            return normalize(I)
    \end{pythoncode}
\end{algorithm}

Before we go further, let us have a look at the properties of the modified Bessel
functions. First, we can see from Fig. \ref{fig:bessel} that,
$I_n(x)$ increases exponentially with increasing $x$.
And at fixed $x$, with increasing order $n$, $I_n(x)$ decreases drastically as well.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{p3_q1_1}
    \caption{The modified Bessel function of the first kind $I_n(x)$ with
        up to $10$th order at $x$ from $1$ to $10$.}
    \label{fig:bessel}
\end{figure}

Then it is natural to assume that our naïve back recursion algorithm will have larger
errors with increasing $x$ and decreasing $n$. Because that is where tiny numerical
errors in previous steps would result in large deviations in later steps.
So, we could presume that:
\begin{theorem}\label{thm:I_n_x}
    If a starting order $N$ satisfies the following condition:
    for $x = 10$, the back-recurred $I_0(x)$ to $I_5(x)$ are all within $6$ decimal
    places of accuracy. Then $N$ will also satisfy the conditions for all $x$ from $1 - 9$.
\end{theorem}

\begin{algorithm}
    \caption{An example}
    \label{lst:find_n}
    \begin{pythoncode}
        NDIGITS = 6


        def errors(x, starting_order):
            I = back_recursion(x, starting_order)
            I_exact = np.array([special.iv(order, x) for order in range(starting_order + 1)])
            return abs(I - I_exact)


        def max_errors(xs, ns):
            return np.array([[errors(x, n).max() for x in xs] for n in ns])


        def find_minimum_order(xs, ns, atol=1 / 10**NDIGITS):
            error_matrix = max_errors(xs, ns)
            for i, row in enumerate(error_matrix):
                if all(row < atol):
                    return ns[i]
        \end{pythoncode}
\end{algorithm}

In Snippet \ref{lst:find_n}, we implement an algorithm that can find the minimum order
needed for us to satisfy the desired criterion.
Here, the constant \code{NDIGITS} specifies how many decimal places are desired.
In function \code{errors}, we compare
our $I_n(x)$ with the SciPy-calculated results at a certain $x = x_0$ and starting order $N$.
By plotting the back recursion figures, we could find that usually, the error goes up
as $n$ decreases from $N$ to $0$ since that is how the numerical errors accumulate.
So the maximal deviation from the exact value is often achieved at $n = 0$, as shown in
Fig. \ref{fig:I_n_10}. However, the statement ``the maximal deviation from the exact value
is achieved at $n = 0$'' is not always true for some small values of $x$. For example,
in Fig. \ref{fig:I_n_3}, we can see the maximal error happens at $n = 11$, which is an
interesting fluctuation that may be caused by numerical inaccuracy. However, this phenomenon
will not change the correctness of Argument \ref{thm:I_n_x}.

\begin{figure} % 2 independent side-by-side figures
    \centering
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{p3_q1_2}
        \caption{The differences between the exact value of $I_n(10)$ and those calculated by
            our naïve back recursion algorithm, where the starting order $N = 15$.}
        \label{fig:I_n_10}
    \end{minipage}
    \hfil
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{p3_1_11}
        \caption{An interesting behavior where the maximal accumulated error happens at
            $n = 11$ when $x$ is small ($x = 3$ here).}
        \label{fig:I_n_3}
    \end{minipage}
\end{figure}

We also write a function \code{plot_errors_x} (Snippet \ref{lst:plot_errors_x}) to
plot errors $\Delta = I_n(10) - I_{n,\textnormal{exact}}(10)$ for each
back recursion starting order $N = 5 - 32$, as shown in Fig. \ref{fig:plot_errors_10}.
Redder scatters denote for larger $N$, and greener scatters denote
smaller $N$. As you can see, for small $N$'s, their deviations from exact values are huge.

\begin{algorithm}
    \caption{An example}
    \label{lst:plot_errors_x}
    \begin{pythoncode}
        def plot_errors_x(x, starting_order, figname="p3_q1_3.pdf"):
            fig, ax = plt.subplots()
            hsv = plt.get_cmap('hsv')
            for order in range(starting_order, 5, -1):
                ax.scatter(
                    range(order + 1), errors(x, order),
                    color=hsv(order / starting_order),
                    label=f"$N={order}$"
                )
            ax.set_xlim(0, starting_order)
            ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            ax.set_xlabel("Order of the modified Bessel function ($n$)")
            ax.set_ylabel(f"$\Delta = I_{{n}}(x={x}) - I_{{n,\\textnormal{{exact}}}}(x={x})$")
            ax.legend(loc="upper right", ncol=4, fontsize=9)
            fig.savefig(figpath(figname))
            return fig, ax
        \end{pythoncode}
\end{algorithm}

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{p3_q1_3}
    \caption{Numerical errors $\Delta = I_n(10) - I_{n,\textnormal{exact}}(10)$
        for all $N$ from $5$ to $32$.}
    \label{fig:plot_errors_10}
\end{figure}

Finally, we will answer the question. See Snippet \ref{lst:find_n},
in function \code{max_errors}, we apply this algorithm to a matrix spanned by
$x = 1 \to 10$ and $n = 5 \to 39$.
And function \code{minimum_steps} is used to filter out the first $N$ which uniformly
satisfy the desired criterion for all $x = 1 - 10$.
Thus, for
%
\begin{equation}
    \sup_{x \in [1, 10]} \lvert I_N(x) - I_{N,\textnormal{exact}}(x) \rvert < 10^{-6},
\end{equation}
%
the minimal $N$ required is $29$.
To be more intuitive, we have also plotted $I_n(x)$ calculated by back recursion
in a matrix of figures ($x = 1 - 10$, and $n = 5 - 35$) and made them into some GIF files.
This can be achieved by invoking the \code{save_plots_gif} function, as shown in
Snippet \ref{lst:gif}. From these figures we can see that $29$ is an appropriate number.

\begin{algorithm}[H]
    \caption{}
    \label{lst:gif}
    \begin{pythoncode}
        def save_plots_gif(x, ns, figname="errors.gif"):
            filenames = []
            for n in ns:
                filename = f"p3_{x}_{n}.png"
                filenames.append(filename)
                plot_errors(x, n, filename)
            with imageio.get_writer(figpath(figname), mode="I", fps=5) as writer:
                for filename in filenames:
                    image = imageio.imread(figpath(filename))
                    writer.append_data(image)

        for x in range(1, 11):
            save_plots_gif(x, range(5, 35), figname=f"errors_{x}.gif")
        \end{pythoncode}
\end{algorithm}

\Question This code also uses the \code{Decimal} module to allow you to do back recursion to many
decimal places of accuracy. Suppose for some reason you need the modified Bessel functions
$I_0(x)$ to $I_5(x)$ accurate to $24$ decimal places for $x$ in the range $1$ to $10$. How
many back recursion steps do you need to achieve this?

\Answer To achieve $24$ decimal places accuracy, the default SciPy \code{special.iv}
is not enough to solve this problem since it uses $64$-bit floating point numbers
and thus only have $15$ digits of accuracy.
So we should write another high-precision back recursion algorithm to represent the exact
values of $I_n(x)$.

So we need to modify our \code{back_recursion} function a little, as shown in
\ref{lst:back_recursion_precise}. Different from function \code{back_recursion}
(Snippet \ref{lst:back_recursion}), now everything in this function is a \code{Decimal}
object.

\begin{algorithm}[H]
    \caption{}
    \label{lst:back_recursion_precise}
    \begin{pythoncode}
        def back_recursion_precise(x, starting_order):
            orders = range(starting_order + 1)
            I = np.fromiter(map(Decimal, orders), Decimal)
            I[-2:] = Decimal(1), Decimal(0)
            for n in reversed(orders[:-2]):  # Orders from `starting_order-2` to 0
                I[n] = I[n + 2] + 2 * (n + 1) / Decimal(x) * I[n + 1]
            return normalize(I)
        \end{pythoncode}
\end{algorithm}

We also need to redefine how we measure the difference between our algorithm and the
``exact algorithm''. However, as we mentioned, we cannot use \code{special.iv} now.
So what could be the exact values?
One idea is to iterate many more steps until we are sure that our
\code{back_recursion_precise} is definitely converged to the exact values.
Therefore, we rewrite the function \code{errors} in Snippet \ref{lst:find_n},
to let it adapt more decimal places, as shown in Snippet \ref{lst:new_errors}.

\begin{algorithm}
    \caption{}
    \label{lst:new_errors}
    \begin{pythoncode}
        NDIGITS = 24


        def errors(x, starting_order):
            if NDIGITS <= 15:
                I = back_recursion(x, starting_order)
                I_exact = np.array([special.iv(order, x) for order in range(starting_order + 1)])
            else:
                I = back_recursion_precise(x, starting_order)
                I_exact = back_recursion_precise(x, starting_order + 100)[:(starting_order + 1)]
            return abs(I - I_exact)


        xs = range(10, 11)
        ns = range(15000, 15100, 1)
        n = find_minimum_order(xs, ns, Decimal(1) / 10**24)
        \end{pythoncode}
\end{algorithm}

If \code{NDIGITS} is smaller than $15$, then using function \code{back_recursion} and
\code{special.iv} is enough to calculate the rough and exact values of $I_n(x)$. So the
\code{errors} function falls back to the one we defined in Snippet \ref{lst:find_n}. On the
other hand, If it is larger than $15$, then we calculate both the rough and exact values of
$I_n(x)$ using \code{back_recursion_precise}, only with the exact value (\code{I_exact}) to
be a certain amount ($m$) more recurrence steps than the rough one (\code{I}). Here, we
choose $m = 100$.
And the rest of the steps are the same as what we did in Question 1.

However, after scanning $N$ for a very large range ($10 - 20000$), I found that this
algorithm is very difficult to converge below $10^{-24}$, especially when $x = 10$.
As we know from the previous question, $I_0(10) \approx 2815.7166284662544$. So it is
very hard to let its deviation to be as small as $10^{-24}$. The best result we
could achieve is when $N = 15009$, and
%
\begin{equation}
    \sup_{x \in [1, 10]} \lvert I_{N}(x) - I_{N+100}(x) \rvert < 10^{-21}.
\end{equation}
%
After $N = 20000$, our computer will throw an overflow error. So we could not
arrive at the exact $N$ for our algorithm accurate to $24$ decimal places.
We have considered changing $m$ from $10$ to $1000$, but the result is still
the same.

